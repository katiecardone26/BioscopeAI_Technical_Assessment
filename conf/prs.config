// set up params
// can be customized by user
params {
    // python path
    my_python = '/opt/conda/bin/python' // path to python in singularity container or docker image
    // plink2 path (MUST BE PLINK2 NOT PLINK1.9)
    my_plink2 = 'plink2' // path to plink2 in singularity container or docker image (plink2 is on the path)
    // fraposa path
    my_fraposa = 'fraposa'
    // pgscatalog path
    my_pgscatalog 'pgscatalog'
    
    // list of chromosomes
    chromosome_list = (1..22)

    /*
    descriptor file that specficies the PGS ID, and pgs weights filename
    pgs id: pgs catalog ID or nickname for PGS
    pgs_weights_filename column: specify PGS weights filenames with FULL file path
    MUST BE A CSV
    descriptor filename:
    */
    input_descriptor_table_filename="${launchDir}/input/prs_descriptor_file.csv"
    /*
    dictionary including names of essential columns in descriptor table
    specifies cohort, ancestry, phenotype and pgs weights filename column names
    */
    input_descriptor_table_colnames = [id_colname: 'PGS_ID',
                                        pgs_weights_full_filpath_colname: 'SCORE_FILEPATH']
    /*
    dictionary that specifies the column names in your PGS output files
    need to specify chromosome column, position column, A1 column, A2 column, variant ID column, and PGS column
    this assumes that all PGS output files have the same column names
    do not change the keys (pos_colname, a1_colname, etc), only change the values accordingly
    */
    score_file_colnames = [chr_colname: 'CHR', // chromosome column name in PGS output file
                pos_colname: 'POS', // pos_colname: 'chr_position', // base pair/position column name
                a1_colname: 'A1', // A1 / effect allele / alternate (ALT) allele column name
                a2_colname: 'A2', // A2 / other allele /reference (REF) allele column name
                pgs_colname: 'PGS'] // PGS column name
    
    /*
    dictionary that specifies validation cohort information
    each key is a cohort nickname (ex: PMBB, UKBB, eMERGE, AOU)
    each key must have nested keys 'plink_prefix', 'plink_suffix', 'plink_file_flag', 'population_subset_file' and 'variant_id format' but change these values accordingly (make sure the values are in quotes)
    plink files must be chromosome separated
    all cohorts must be in the same genome build as each other and as the PGS outputs
    */
    validation_populations = [my_population:
                    [vcf_prefix: "${launchDir}/input/my_vcf.chr", // vcf file name BEFORE chromosome number
                    vcf_suffix: '', // vcf file name AFTER chromosome number
                    population_subset_file: "${launchDir}/input/my_sample_list.txt", // sample list
                    population_subset_file_id_col: 'ID', // ID column name in population subset file. Use a numeric index (based on python, so first column name would be 0) if there is no column name
                    population_subset_file_delim: '\t', // Delimiter population subset file. Use any delimiter if it just a one column file. Possible options- tab: '\t', space: '\s+', comma: ','
                    related_list: "${launchDir}/input/related_list.txt"] // list of related individuals
    ]
    // reference panel plink prefix (files must be chromosome combined and plink2 files)
    ref_panel_plink_prefix = "${launchDir}/ref_panel/1KG"
    // ref panel key
    ref_panel_key = '1KG'
    // QC metrics for reference panel PCA
    ref_hwe_threshold = '0.0001' // hardy weinberg equilibrium
    ref_maf_threshold = '0.05' // minor allele frequency
    ref_geno_threshold = '0.1' // variant missingness
    ref_mind_threshold = '0.1' // sample missinging
    ref_ld_prune_params = "1000 50 0.05" // ld pruning paramaters

    // plink score parameters
    dosage_transformation = '' /* defines whether dosage information is transformed
                                possible choices:
                                '' (blank) = basic allele dosages used (0..2 on diploid chromosomes, 0..1 on haploid, male chrX encoding controlled by --xchr-model)
                                'center' = translates all dosages to mean zero. (More precisely, they are translated based on allele frequencies, which you can control with --read-freq)
                                'variance-standardize' = linearly transforms each variant's dosage vector to have mean zero, variance 1 (cannot be used with chrX)
                                'dominant' = causes dosages greater than 1 to be treated as 1 (cannot be used with chrX)
                                'recessive' = uses max(dosage - 1, 0) on diploid chromosomes (cannot be used with chrX)
                            */
    xchr_model = '2'  /*  PLINK 2 dosages are on a 0..2 scale on regular diploid chromosomes, and 0..1 on regular haploid chromosomes.
                        However, chrX doesn't fit neatly in either of those categories. --xchr-model lets you control its encoding in several contexts
                        possible choices:
                        '0' = Skip chrX
                        '1' = Male dosages are on a 0..1 scale on chrX, while females are 0..2. This was the PLINK 1.x default
                        '2' = Males and females are both on a 0..2 scale on chrX. This is the PLINK 2 default
                    */
    read_freq = 'auto'    /*  the --read-freq loads in allele frequency estimates from a --freq (PLINK 1.x ok), --geno-counts, or PLINK 1.9 --freqx report, instead of imputing them from the immediate dataset
                        possible file types (by suffix): .afreq/.acount/.gcount/.freq/.frq/.frq.count/.frqx
                        possible choices:
                        'auto' = not specifying an allele frequency file, instead imputing them from the dataset being used
                        'filename' = filename of an allele frequency file
                    */
    no_mean_imputation = '' /*  By default, copies of unnamed alleles contribute zero to score, while missing genotypes contribute an amount proportional to the loaded (via --read-freq) or imputed allele frequency.
                                To throw out missing observations instead (decreasing the denominator in the final average when this happens), use the 'no-mean-imputation' modifier.
                                possible choices:
                                '' (blank) = not using this modifier
                                'no-mean-imputation' = using this modifier
                            */
    independent_se = '' /*  The 'se' modifier causes the input coefficients to be treated as independent standard errors;
                            in this case, standard errors for the score average/sum are reported, under a Gaussian approximation.
                            (This will of course tend to underestimate standard errors when scored variants are in LD.)
                            possible choices:
                            '' (blank) = not using this modifier
                            'se' = using this modifier
                        */

    // high risk percentile cutoff threhold (whole number)
    percentile_cutoff = '95'
}
